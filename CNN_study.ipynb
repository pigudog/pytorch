{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建卷积神经网络\n",
    "- 卷积神经网络的输入层与传统神经网络有些区别，需要重新设计，但是训练模块是基本一致的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\download\\python\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 首先读取数据\n",
    "- 分别构建训练接和检测集（验证集）\n",
    "- DataLoader来迭代取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "input_size = 28 # 图像的总尺寸是28*28\n",
    "num_classes = 10\n",
    "num_epochs = 3\n",
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集\n",
    "train_dataset = datasets.MNIST(root='./data',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "# 测试集\n",
    "test_dataset = datasets.MNIST(root='./data',\n",
    "                              train = False,\n",
    "                               transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建batch数据\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积网络模块构建\n",
    "- 一般卷积层，relu层是一起的，两次卷积一次池化\n",
    "- 注意卷积最后结果还是一个特征图，需要把图转化为向量再做分类或者回归任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import forward\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1 = nn.Sequential(  # 输入大小为（1,28,28）\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,          # 灰度图\n",
    "                out_channels=16,        # 要得到多少个特征图\n",
    "                kernel_size=5,          # 卷积核大小\n",
    "                stride=1,               # 步长\n",
    "                padding=2               # 如果希望卷积后的特征图的大小跟原来一样,需要设置padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                          # 此时输出的特征图为（16，28，28） \n",
    "            nn.ReLU(),                  # ReLU层\n",
    "            nn.MaxPool2d(kernel_size=2),# 进行池化操作（2x2），输出结果为(16,14,14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(     # 下个一个卷积输入为（16，14，14）\n",
    "            nn.Conv2d(16,32,5,1,2),     # 输出（32，14，14）\n",
    "            nn.ReLU(),                  # ReLU层\n",
    "            nn.MaxPool2d(2)             # 输出（32，7，7）\n",
    "        )\n",
    "        self.out = nn.Linear(32*7*7,10) # 全连接层得到的结果\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0),-1)        # flatten操作，结果是(batch_size,32x7x7)\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这将准去率作为最终的评估标准\n",
    "def accuracy(predictions,labels):\n",
    "    pred = torch.max(predictions.data,1)[1]\n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum()\n",
    "    return rights,len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前epoch:0 [0/60000 (0%)]\t损失:2.314794\t训练集准确率:9.38%\t检测集准确率:18.42%\n",
      "当前epoch:0 [6400/60000 (11%)]\t损失:0.173669\t训练集准确率:85.32%\t检测集准确率:96.22%\n",
      "当前epoch:0 [12800/60000 (21%)]\t损失:0.062894\t训练集准确率:90.59%\t检测集准确率:96.90%\n",
      "当前epoch:0 [19200/60000 (32%)]\t损失:0.062483\t训练集准确率:92.68%\t检测集准确率:96.75%\n",
      "当前epoch:0 [25600/60000 (43%)]\t损失:0.028073\t训练集准确率:93.86%\t检测集准确率:97.67%\n",
      "当前epoch:0 [32000/60000 (53%)]\t损失:0.081514\t训练集准确率:94.55%\t检测集准确率:97.38%\n",
      "当前epoch:0 [38400/60000 (64%)]\t损失:0.030849\t训练集准确率:95.00%\t检测集准确率:97.95%\n",
      "当前epoch:0 [44800/60000 (75%)]\t损失:0.019593\t训练集准确率:95.39%\t检测集准确率:97.92%\n",
      "当前epoch:0 [51200/60000 (85%)]\t损失:0.032896\t训练集准确率:95.66%\t检测集准确率:98.00%\n",
      "当前epoch:0 [57600/60000 (96%)]\t损失:0.054455\t训练集准确率:95.85%\t检测集准确率:97.74%\n",
      "当前epoch:1 [0/60000 (0%)]\t损失:0.219851\t训练集准确率:96.88%\t检测集准确率:98.43%\n",
      "当前epoch:1 [6400/60000 (11%)]\t损失:0.056785\t训练集准确率:97.94%\t检测集准确率:98.54%\n",
      "当前epoch:1 [12800/60000 (21%)]\t损失:0.067520\t训练集准确率:98.14%\t检测集准确率:97.93%\n",
      "当前epoch:1 [19200/60000 (32%)]\t损失:0.051063\t训练集准确率:98.12%\t检测集准确率:98.11%\n",
      "当前epoch:1 [25600/60000 (43%)]\t损失:0.055678\t训练集准确率:98.09%\t检测集准确率:98.27%\n",
      "当前epoch:1 [32000/60000 (53%)]\t损失:0.086221\t训练集准确率:98.09%\t检测集准确率:98.69%\n",
      "当前epoch:1 [38400/60000 (64%)]\t损失:0.018331\t训练集准确率:98.06%\t检测集准确率:98.19%\n",
      "当前epoch:1 [44800/60000 (75%)]\t损失:0.017086\t训练集准确率:98.09%\t检测集准确率:98.63%\n",
      "当前epoch:1 [51200/60000 (85%)]\t损失:0.016669\t训练集准确率:98.13%\t检测集准确率:98.64%\n",
      "当前epoch:1 [57600/60000 (96%)]\t损失:0.087025\t训练集准确率:98.10%\t检测集准确率:98.57%\n",
      "当前epoch:2 [0/60000 (0%)]\t损失:0.010060\t训练集准确率:100.00%\t检测集准确率:98.62%\n",
      "当前epoch:2 [6400/60000 (11%)]\t损失:0.010236\t训练集准确率:98.72%\t检测集准确率:98.34%\n",
      "当前epoch:2 [12800/60000 (21%)]\t损失:0.039905\t训练集准确率:98.31%\t检测集准确率:97.78%\n",
      "当前epoch:2 [19200/60000 (32%)]\t损失:0.093796\t训练集准确率:98.32%\t检测集准确率:98.42%\n",
      "当前epoch:2 [25600/60000 (43%)]\t损失:0.095453\t训练集准确率:98.30%\t检测集准确率:98.63%\n",
      "当前epoch:2 [32000/60000 (53%)]\t损失:0.009870\t训练集准确率:98.31%\t检测集准确率:98.56%\n",
      "当前epoch:2 [38400/60000 (64%)]\t损失:0.050689\t训练集准确率:98.35%\t检测集准确率:98.20%\n",
      "当前epoch:2 [44800/60000 (75%)]\t损失:0.078299\t训练集准确率:98.33%\t检测集准确率:98.46%\n",
      "当前epoch:2 [51200/60000 (85%)]\t损失:0.043867\t训练集准确率:98.32%\t检测集准确率:98.79%\n",
      "当前epoch:2 [57600/60000 (96%)]\t损失:0.065956\t训练集准确率:98.34%\t检测集准确率:98.68%\n"
     ]
    }
   ],
   "source": [
    "# 训练网络模型\n",
    "# 实例化\n",
    "net = CNN()\n",
    "# 损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 优化器\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.01) # 定义优化器\n",
    "\n",
    "# 开始训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    train_rights = []\n",
    "    for batch_idx,(data,target) in enumerate(train_loader): # 针对容器中的每一个批进行循环\n",
    "        net.train()\n",
    "        output = net(data)\n",
    "        loss = criterion(output,target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        right = accuracy(output,target)\n",
    "        train_rights.append(right)\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            net.eval()\n",
    "            val_rights = []\n",
    "            for (data,target) in test_loader:\n",
    "                output = net(data)\n",
    "                right = accuracy(output,target)\n",
    "                val_rights.append(right)\n",
    "                \n",
    "            # 准确率计算\n",
    "            train_r = (sum([tup[0] for tup in train_rights]),sum([tup[1] for tup in train_rights]))\n",
    "            val_r = (sum([tup[0] for tup in val_rights]),sum([tup[1] for tup in val_rights]))\n",
    "            \n",
    "            print(\"当前epoch:{} [{}/{} ({:.0f}%)]\\t损失:{:6f}\\t训练集准确率:{:.2f}%\\t检测集准确率:{:.2f}%\".format(\n",
    "                epoch,batch_idx*batch_size,len(train_loader.dataset),\n",
    "                100.*batch_idx/len(train_loader),\n",
    "                loss.data,\n",
    "                100.*train_r[0].numpy()/train_r[1],\n",
    "                100.*val_r[0]/val_r[1]\n",
    "            ))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu113\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import forward\n",
    "# 这将准去率作为最终的评估标准\n",
    "def accuracy(predictions,labels):\n",
    "    pred = torch.max(predictions.data.cuda(),1)[1]\n",
    "    rights = pred.eq(labels.cuda().data.view_as(pred.cuda())).sum()\n",
    "    return rights,len(labels)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1 = nn.Sequential(  # 输入大小为（1,28,28）\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,          # 灰度图\n",
    "                out_channels=16,        # 要得到多少个特征图\n",
    "                kernel_size=5,          # 卷积核大小\n",
    "                stride=1,               # 步长\n",
    "                padding=2               # 如果希望卷积后的特征图的大小跟原来一样,需要设置padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                          # 此时输出的特征图为（16，28，28） \n",
    "            nn.ReLU(),                  # ReLU层\n",
    "            nn.MaxPool2d(kernel_size=2),# 进行池化操作（2x2），输出结果为(16,14,14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(     # 下个一个卷积输入为（16，14，14）\n",
    "            nn.Conv2d(16,32,5,1,2),     # 输出（32，14，14）\n",
    "            nn.ReLU(),                  # ReLU层\n",
    "            nn.MaxPool2d(2)             # 输出（32，7，7）\n",
    "        )\n",
    "        self.out = nn.Linear(32*7*7,10) # 全连接层得到的结果\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x.cuda())\n",
    "        x = self.conv2(x.cuda())\n",
    "        x = x.view(x.size(0),-1)        # flatten操作，结果是(batch_size,32x7x7)\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1d2d75b3bb0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建batch数据\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前epoch:0 [0/60000 (0%)]\t损失:2.300650\t训练集准确率:6.25%\t检测集准确率:9.86%\n",
      "当前epoch:0 [6400/60000 (11%)]\t损失:0.146061\t训练集准确率:80.57%\t检测集准确率:94.02%\n",
      "当前epoch:0 [12800/60000 (21%)]\t损失:0.158085\t训练集准确率:88.00%\t检测集准确率:96.00%\n",
      "当前epoch:0 [19200/60000 (32%)]\t损失:0.029171\t训练集准确率:90.86%\t检测集准确率:96.48%\n",
      "当前epoch:0 [25600/60000 (43%)]\t损失:0.059782\t训练集准确率:92.47%\t检测集准确率:96.72%\n",
      "当前epoch:0 [32000/60000 (53%)]\t损失:0.150853\t训练集准确率:93.36%\t检测集准确率:97.76%\n",
      "当前epoch:0 [38400/60000 (64%)]\t损失:0.125140\t训练集准确率:93.91%\t检测集准确率:97.20%\n",
      "当前epoch:0 [44800/60000 (75%)]\t损失:0.026381\t训练集准确率:94.43%\t检测集准确率:97.66%\n",
      "当前epoch:0 [51200/60000 (85%)]\t损失:0.043444\t训练集准确率:94.78%\t检测集准确率:97.98%\n",
      "当前epoch:0 [57600/60000 (96%)]\t损失:0.009474\t训练集准确率:95.05%\t检测集准确率:97.07%\n",
      "当前epoch:1 [0/60000 (0%)]\t损失:0.115455\t训练集准确率:95.31%\t检测集准确率:97.89%\n",
      "当前epoch:1 [6400/60000 (11%)]\t损失:0.230221\t训练集准确率:97.34%\t检测集准确率:97.54%\n",
      "当前epoch:1 [12800/60000 (21%)]\t损失:0.037741\t训练集准确率:97.54%\t检测集准确率:97.85%\n",
      "当前epoch:1 [19200/60000 (32%)]\t损失:0.185074\t训练集准确率:97.61%\t检测集准确率:97.91%\n",
      "当前epoch:1 [25600/60000 (43%)]\t损失:0.039914\t训练集准确率:97.56%\t检测集准确率:98.29%\n",
      "当前epoch:1 [32000/60000 (53%)]\t损失:0.082285\t训练集准确率:97.64%\t检测集准确率:98.36%\n",
      "当前epoch:1 [38400/60000 (64%)]\t损失:0.033009\t训练集准确率:97.71%\t检测集准确率:98.27%\n",
      "当前epoch:1 [44800/60000 (75%)]\t损失:0.064672\t训练集准确率:97.74%\t检测集准确率:97.84%\n",
      "当前epoch:1 [51200/60000 (85%)]\t损失:0.001002\t训练集准确率:97.79%\t检测集准确率:98.60%\n",
      "当前epoch:1 [57600/60000 (96%)]\t损失:0.006278\t训练集准确率:97.83%\t检测集准确率:98.18%\n",
      "当前epoch:2 [0/60000 (0%)]\t损失:0.009161\t训练集准确率:100.00%\t检测集准确率:98.43%\n",
      "当前epoch:2 [6400/60000 (11%)]\t损失:0.050294\t训练集准确率:98.38%\t检测集准确率:98.33%\n",
      "当前epoch:2 [12800/60000 (21%)]\t损失:0.002123\t训练集准确率:98.45%\t检测集准确率:98.52%\n",
      "当前epoch:2 [19200/60000 (32%)]\t损失:0.007012\t训练集准确率:98.45%\t检测集准确率:98.07%\n",
      "当前epoch:2 [25600/60000 (43%)]\t损失:0.098868\t训练集准确率:98.25%\t检测集准确率:97.92%\n",
      "当前epoch:2 [32000/60000 (53%)]\t损失:0.014492\t训练集准确率:98.21%\t检测集准确率:98.32%\n",
      "当前epoch:2 [38400/60000 (64%)]\t损失:0.173540\t训练集准确率:98.18%\t检测集准确率:98.15%\n",
      "当前epoch:2 [44800/60000 (75%)]\t损失:0.015830\t训练集准确率:98.13%\t检测集准确率:98.51%\n",
      "当前epoch:2 [51200/60000 (85%)]\t损失:0.023388\t训练集准确率:98.14%\t检测集准确率:98.61%\n",
      "当前epoch:2 [57600/60000 (96%)]\t损失:0.114662\t训练集准确率:98.15%\t检测集准确率:98.60%\n"
     ]
    }
   ],
   "source": [
    "# 训练网络模型\n",
    "# 实例化\n",
    "net = CNN()\n",
    "net.to(\"cuda\")\n",
    "# 损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 优化器\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.01) # 定义优化器\n",
    "\n",
    "# 开始训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    train_rights = []\n",
    "    for batch_idx,(data,target) in enumerate(train_loader): # 针对容器中的每一个批进行循环\n",
    "        net.train()\n",
    "        output = net(data)\n",
    "        loss = criterion(output.cuda(),target.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        right = accuracy(output,target)\n",
    "        train_rights.append(right)\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            net.eval()\n",
    "            val_rights = []\n",
    "            for (data,target) in test_loader:\n",
    "                output = net(data)\n",
    "                right = accuracy(output,target)\n",
    "                val_rights.append(right)\n",
    "                \n",
    "            # 准确率计算\n",
    "            train_r = (sum([tup[0] for tup in train_rights]),sum([tup[1] for tup in train_rights]))\n",
    "            val_r = (sum([tup[0] for tup in val_rights]),sum([tup[1] for tup in val_rights]))\n",
    "            \n",
    "            print(\"当前epoch:{} [{}/{} ({:.0f}%)]\\t损失:{:6f}\\t训练集准确率:{:.2f}%\\t检测集准确率:{:.2f}%\".format(\n",
    "                epoch,batch_idx*batch_size,len(train_loader.dataset),\n",
    "                100.*batch_idx/len(train_loader),\n",
    "                loss.data,\n",
    "                100.*train_r[0]/train_r[1],\n",
    "                100.*val_r[0]/val_r[1]\n",
    "            ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e12f081f3b69c47b407a411e35ba4814a2bf694e6a041dab3adb1673ea66113c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
