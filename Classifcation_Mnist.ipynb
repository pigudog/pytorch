{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minist Classification task\n",
    "- Construction of neural networks as well as training methods and common function analysis\n",
    "- module of **torch.nn.function** \n",
    "- modele of **nn.Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset from Minist\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pathlib的mkdir接收两个参数：\n",
    "\n",
    "- parents：如果父目录不存在，是否创建父目录。\n",
    "- exist_ok：只有在目录不存在时创建目录，目录已存在时不会抛出异常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 第二步，读数据（前两步先不用管）\n",
    "# with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "# #     (x_train, y_train)训练集的样本数据和对应的标签, (x_valid, y_valid)验证集的样本数据和对应标签\n",
    "#         ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这儿错误的原因是deeplearning.net已经不能访问了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle module\n",
    "它能够实现任意对象与文本之间的相互转化，也可以实现任意对象与二进制之间的相互转化。也就是说，pickle 可以实现 Python 对象的存储及恢复。\n",
    "\n",
    "pickle 模块提供了以下 4 个函数供我们使用：\n",
    "- dumps()：将 Python 中的对象序列化成二进制对象，并返回；\n",
    "- loads()：读取给定的二进制对象数据，并将其转换为 Python 对象；\n",
    "- dump()：将 Python 中的对象序列化成二进制对象，并写入文件；\n",
    "- load()：读取指定的序列化数据文件，并返回对象。\n",
    "\n",
    "看似强大的 pickle 模块，其实也有它的短板，即 pickle 不支持并发地访问持久性对象，在复杂的系统环境下，尤其是读取海量数据时，使用 pickle 会使整个系统的I/O读取性能成为瓶颈。这种情况下，可以使用 ZODB。\n",
    "\n",
    "ZODB 是一个健壮的、多用户的和面向对象的数据库系统，专门用于存储 Python 语言中的对象数据，它能够存储和管理任意复杂的 Python 对象，并支持事务操作和并发控制。并且，ZODB 也是在 Python 的序列化操作基础之上实现的，因此要想有效地使用 ZODB，必须先学好 pickle。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pre-processing\n",
    "\n",
    "# mnist = fetch_openml('mnist_784', data_home='.')\n",
    "# X = mnist.data / 255\n",
    "# y = mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel1       0.0\n",
       "pixel2       0.0\n",
       "pixel3       0.0\n",
       "pixel4       0.0\n",
       "pixel5       0.0\n",
       "            ... \n",
       "pixel780    62.0\n",
       "pixel781     0.0\n",
       "pixel782     0.0\n",
       "pixel783     0.0\n",
       "pixel784     0.0\n",
       "Length: 784, dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=1/7, random_state=0)  # 数据切分，训练集：测试集=6:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01960784, 0.47058824,\n",
       "        0.78039216, 0.99607843, 1.        , 0.74901961, 0.43529412,\n",
       "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.27058824, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.48627451, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00392157, 0.43921569,\n",
       "        0.63529412, 0.03921569, 0.03921569, 0.03921569, 0.8       ,\n",
       "        0.98823529, 0.62352941, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.28627451, 0.94117647,\n",
       "        0.99215686, 0.90196078, 0.04313725, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.09411765, 0.80784314, 0.99215686,\n",
       "        0.99215686, 0.6745098 , 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01960784, 0.38823529, 0.94509804, 0.99215686, 0.99215686,\n",
       "        0.94901961, 0.46666667, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.42352941, 0.99215686, 0.99215686, 0.99215686, 0.78431373,\n",
       "        0.44313725, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.20392157, 0.99215686, 0.99215686, 0.99215686, 0.2       ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01176471, 0.16078431, 0.6745098 , 0.99215686, 0.70588235,\n",
       "        0.36470588, 0.01568627, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.63137255, 0.95294118,\n",
       "        0.99215686, 0.85882353, 0.39607843, 0.05882353, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16078431,\n",
       "        0.36862745, 0.64313725, 0.99215686, 0.7254902 , 0.2       ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00784314, 0.87058824, 0.99215686, 0.95294118,\n",
       "        0.25490196, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.52941176, 0.99215686, 0.99215686,\n",
       "        0.72941176, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.91372549, 0.99215686, 0.98431373,\n",
       "        0.63921569, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.25098039, 0.97647059, 0.99215686, 0.61960784,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0627451 , 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.03529412,\n",
       "        0.38431373, 0.92941176, 0.99215686, 0.99215686, 0.30588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.73333333, 0.59215686, 0.        ,\n",
       "        0.        , 0.        , 0.00784314, 0.26666667, 0.71372549,\n",
       "        0.99215686, 0.99215686, 0.96078431, 0.43921569, 0.03529412,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.71764706, 0.98039216, 0.57254902,\n",
       "        0.45098039, 0.45098039, 0.79215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.67058824, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.12156863, 0.59215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.95686275, 0.62745098, 0.02352941, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01960784, 0.29803922,\n",
       "        0.61176471, 0.82745098, 0.65882353, 0.74117647, 0.43137255,\n",
       "        0.15294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "# 注意从dataframe中取下来的series没有reshape的功能\n",
    "# 解决办法：用values方法将Series对象转化成numpy的ndarray，再用ndarray的reshape方法.\n",
    "X_train.iloc[1].values.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23377b13430>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "# x_train[0] 一维的784个数据.reshape成 28*28 的，cmap 用一个灰度图去做\n",
    "pyplot.imshow(X_train.iloc[1].values.reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "59996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "59997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "59998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "59999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "1          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "2          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "3          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "4          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "59995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "59996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "59997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "59998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "59999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0           0.0       0.0       0.0       0.0       0.0  \n",
       "1           0.0       0.0       0.0       0.0       0.0  \n",
       "2           0.0       0.0       0.0       0.0       0.0  \n",
       "3           0.0       0.0       0.0       0.0       0.0  \n",
       "4           0.0       0.0       0.0       0.0       0.0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "59995       0.0       0.0       0.0       0.0       0.0  \n",
       "59996       0.0       0.0       0.0       0.0       0.0  \n",
       "59997       0.0       0.0       0.0       0.0       0.0  \n",
       "59998       0.0       0.0       0.0       0.0       0.0  \n",
       "59999       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[60000 rows x 784 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28926    7\n",
       "9080     3\n",
       "52804    0\n",
       "28094    1\n",
       "46585    2\n",
       "        ..\n",
       "21243    7\n",
       "45891    8\n",
       "42613    7\n",
       "43567    1\n",
       "68268    1\n",
       "Name: class, Length: 60000, dtype: category\n",
       "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56267</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14849</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62726</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47180</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63055</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7991</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39237</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21866</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38802</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "10840     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "56267     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "14849     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "62726     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "47180     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "63055     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "7991      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "39237     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "21866     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "38802     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "10840      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "56267      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "14849      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "62726      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "47180      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "63055      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "7991       0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "39237      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "21866      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "38802      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "10840       0.0       0.0       0.0       0.0       0.0  \n",
       "56267       0.0       0.0       0.0       0.0       0.0  \n",
       "14849       0.0       0.0       0.0       0.0       0.0  \n",
       "62726       0.0       0.0       0.0       0.0       0.0  \n",
       "47180       0.0       0.0       0.0       0.0       0.0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "63055       0.0       0.0       0.0       0.0       0.0  \n",
       "7991        0.0       0.0       0.0       0.0       0.0  \n",
       "39237       0.0       0.0       0.0       0.0       0.0  \n",
       "21866       0.0       0.0       0.0       0.0       0.0  \n",
       "38802       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[10000 rows x 784 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10840    0\n",
       "56267    4\n",
       "14849    1\n",
       "62726    2\n",
       "47180    7\n",
       "        ..\n",
       "63055    7\n",
       "7991     6\n",
       "39237    1\n",
       "21866    3\n",
       "38802    0\n",
       "Name: class, Length: 10000, dtype: category\n",
       "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)          # 将features转为numpy格式\n",
    "X_test = np.array(X_test)\n",
    "# y_train = list(map(int, y_train))    # 将label的str类型转为int\n",
    "# y_test = list(map(int, y_test))\n",
    "y_train = np.array(y_train,dtype=float)   # 将label的str类型转为int\n",
    "y_test = np.array(y_test,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转化为数据格式\n",
    "import torch\n",
    "# torch 放在 GPU 中跑，底层结构不同。tensor 张量（矩阵）一切处理的数据都是张量，TensorFlow 张量（矩阵）在流动，矩阵在变换\n",
    "# ndarray格式 torch 用不了\n",
    "# 使用 map 将数组格式映射为 tensor 格式\n",
    "# x_train, y_train, x_valid, y_valid = map(torch.from_numpy(), (X_train, y_train, X_test, y_test))\n",
    "x_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train,dtype=torch.long)\n",
    "x_valid = torch.tensor(X_test,dtype=torch.float32)\n",
    "y_valid = torch.tensor(y_test,dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.0849, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 设置损失函数和全连接层\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 计算损失\n",
    "loss_func = F.cross_entropy# 用loss_func的时候要传入（pre,y）预测值和标签\n",
    "\n",
    "# 全连接层\n",
    "def model(xb):\n",
    "    return xb.mm(weights) + bias\n",
    "\n",
    "# 设置参数\n",
    "# batchsize：一次性训练的样本个数\n",
    "bs = 64\n",
    "# xw + b,w哪里来，可以自己做初始化，权重参数随机初始化，\n",
    "# x 的规格。64*784（每个样本 784 个特征）\n",
    "xb = x_train[0:bs]  # a mini-batch from x\n",
    "yb = y_train[0:bs]\n",
    "# 随机初始化权重参数 w：784*10 ，需要梯度\n",
    "weights = torch.randn([784, 10], dtype = torch.float,  requires_grad = True) \n",
    "bs = 64\n",
    "# 偏执可以是随机数，可以常数，对结果的影响是非常小的\n",
    "bias = torch.zeros(10, requires_grad=True)\n",
    "\n",
    "# model(xb) 预测值, yb标签\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.functional\n",
    "\n",
    "一般情况下，如果模型有可学习的参数，最好用nn.Module，其他情况nn.functional(如激活函数、损失函数)相对更简单一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化网络结构\n",
    "from torch import nn\n",
    "\n",
    "# 继承不能改\n",
    "class Mnist_NN(nn.Module):\n",
    "#     构造函数（接下来你会用到哪一层，哪一些操作，每一层的设计要给出来），先定义好第一个 FC，第二个 FC，输出层，dropout\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#       第一个隐层：输入 784 个像素点（第一行有 784 列），输出 128 个特征（输出 128 行）\n",
    "        self.hidden1 = nn.Linear(784, 128)\n",
    "#       第二个隐层：输入（第一个隐层的输出） 128 个像素点，输出 256 个特征\n",
    "        self.hidden2 = nn.Linear(128, 256)\n",
    "#       输出层\n",
    "        self.out  = nn.Linear(256, 10)\n",
    "#       按照 50%的比例来杀死特征点\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "# torch 中的前向传播是需要自己做定义，反向传播是自动的，torch 反向传播一行代码给你实现\n",
    "# 前向传播\n",
    "# x 是 batch 值，x 每一步要走什么都是要自己定义的\n",
    "    def forward(self, x):\n",
    "#       第一步走h1，\n",
    "        x = F.relu(self.hidden1(x))\n",
    "#       每一个 FC 层都要加上 dropout，除了最后一层输出层\n",
    "        x = self.dropout(x)\n",
    "#       h2 层\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.dropout(x)\n",
    "#       输出层  \n",
    "        x = self.out(x)\n",
    "        return x\n",
    "        \n",
    "# 首先定义好自己的网络结构，定义一个类，类当中构造函数要用啥，每一层要怎么去走，要自己去定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist_NN(\n",
      "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (hidden2): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Mnist_NN()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1.weight Parameter containing:\n",
      "tensor([[ 0.0124,  0.0047, -0.0074,  ...,  0.0318, -0.0087,  0.0107],\n",
      "        [-0.0303, -0.0098, -0.0353,  ...,  0.0345,  0.0135, -0.0278],\n",
      "        [-0.0330,  0.0274, -0.0025,  ..., -0.0173,  0.0009, -0.0134],\n",
      "        ...,\n",
      "        [-0.0166, -0.0201,  0.0126,  ..., -0.0039, -0.0325, -0.0143],\n",
      "        [-0.0193, -0.0339,  0.0047,  ...,  0.0332,  0.0133,  0.0018],\n",
      "        [ 0.0135, -0.0182, -0.0349,  ...,  0.0184, -0.0150, -0.0329]],\n",
      "       requires_grad=True) torch.Size([128, 784])\n",
      "hidden1.bias Parameter containing:\n",
      "tensor([ 5.8502e-03,  1.2615e-02,  2.6641e-02, -3.5045e-02,  1.0497e-02,\n",
      "        -2.8817e-02, -8.8946e-03, -1.0250e-02,  4.5343e-03, -2.8259e-02,\n",
      "        -9.7268e-03,  1.5720e-02,  4.6808e-03, -3.1617e-02, -2.1273e-02,\n",
      "        -1.9286e-02,  2.8239e-02, -6.3414e-03,  2.5660e-02, -1.5734e-02,\n",
      "         7.8884e-03,  2.2447e-02,  2.6967e-02,  1.5747e-02, -5.9187e-03,\n",
      "         2.1809e-02, -3.2418e-02, -1.8322e-02,  1.6703e-02,  3.1579e-02,\n",
      "         7.8138e-03, -3.0858e-02,  3.4731e-02,  2.7742e-02,  2.4829e-03,\n",
      "         1.1325e-05,  2.4762e-03, -2.7139e-02, -2.9548e-02,  3.3235e-02,\n",
      "         3.1252e-02, -3.4954e-03,  1.8850e-02, -5.8819e-03, -2.1546e-02,\n",
      "        -5.7031e-03, -1.7660e-02,  2.8489e-02, -1.5267e-02, -2.9419e-02,\n",
      "         2.9019e-02,  1.5615e-02,  7.7730e-03,  7.5922e-04, -1.7167e-02,\n",
      "         6.8441e-03,  2.7971e-02, -6.6850e-03,  9.3528e-03, -9.4616e-03,\n",
      "        -1.1531e-02, -1.5682e-03,  3.2897e-02,  2.0884e-02, -1.2831e-02,\n",
      "         2.2311e-02, -1.7735e-02, -1.7449e-02,  1.2110e-02, -1.8305e-02,\n",
      "        -1.0348e-02,  2.7599e-02, -2.9589e-02,  3.4922e-02,  2.1613e-02,\n",
      "         1.7155e-02,  1.1487e-03,  3.9096e-03, -1.1263e-02,  2.9590e-02,\n",
      "         1.0447e-03,  1.5219e-02,  2.2466e-02, -2.2292e-04,  2.5084e-02,\n",
      "         4.7535e-03, -1.9417e-02, -1.8137e-02,  3.4199e-02,  5.2939e-04,\n",
      "        -1.5205e-02, -1.8592e-03,  1.6634e-02, -1.2569e-02,  1.9351e-02,\n",
      "        -3.1388e-02,  6.5179e-03,  1.9903e-02,  3.4914e-02,  1.6131e-02,\n",
      "         1.6237e-02,  2.2273e-02, -8.3345e-03, -1.5976e-03, -1.8544e-02,\n",
      "        -1.4382e-02, -3.9453e-03,  2.3221e-02,  1.3921e-02,  1.9836e-02,\n",
      "        -2.8161e-02,  3.4831e-02,  6.9678e-03, -2.9086e-02, -8.2691e-03,\n",
      "         1.3843e-02,  1.5806e-03,  2.6835e-02,  2.6921e-03,  6.3366e-03,\n",
      "         2.7364e-03, -2.1869e-03, -3.2478e-02,  9.7168e-03,  3.3959e-02,\n",
      "         1.4347e-02,  2.4297e-02,  1.4800e-02], requires_grad=True) torch.Size([128])\n",
      "hidden2.weight Parameter containing:\n",
      "tensor([[-0.0151, -0.0731,  0.0545,  ..., -0.0291,  0.0010, -0.0072],\n",
      "        [-0.0782,  0.0087, -0.0310,  ..., -0.0196,  0.0366,  0.0288],\n",
      "        [-0.0123,  0.0740,  0.0480,  ..., -0.0221, -0.0245,  0.0179],\n",
      "        ...,\n",
      "        [ 0.0634,  0.0558,  0.0577,  ..., -0.0852, -0.0330, -0.0041],\n",
      "        [-0.0139, -0.0052, -0.0142,  ..., -0.0877, -0.0795, -0.0577],\n",
      "        [ 0.0320, -0.0589, -0.0357,  ...,  0.0327,  0.0290,  0.0825]],\n",
      "       requires_grad=True) torch.Size([256, 128])\n",
      "hidden2.bias Parameter containing:\n",
      "tensor([ 0.0033, -0.0854, -0.0736,  0.0568, -0.0767, -0.0262,  0.0237,  0.0198,\n",
      "        -0.0125,  0.0837, -0.0673, -0.0608,  0.0879,  0.0274,  0.0373, -0.0040,\n",
      "         0.0365,  0.0053, -0.0705, -0.0522,  0.0600, -0.0713,  0.0389, -0.0404,\n",
      "        -0.0169, -0.0164,  0.0647,  0.0119,  0.0470, -0.0015, -0.0842,  0.0204,\n",
      "         0.0830,  0.0693,  0.0536, -0.0374, -0.0178, -0.0758,  0.0402,  0.0620,\n",
      "         0.0829,  0.0246,  0.0584,  0.0296,  0.0189,  0.0764, -0.0851, -0.0161,\n",
      "         0.0793, -0.0235, -0.0661,  0.0104,  0.0616,  0.0816, -0.0104, -0.0507,\n",
      "         0.0696,  0.0308,  0.0350, -0.0253, -0.0792,  0.0666, -0.0456,  0.0267,\n",
      "        -0.0027,  0.0015,  0.0150,  0.0252,  0.0092,  0.0112, -0.0501, -0.0238,\n",
      "         0.0309,  0.0491,  0.0162, -0.0869, -0.0238, -0.0181, -0.0103,  0.0177,\n",
      "        -0.0330,  0.0597, -0.0853,  0.0349, -0.0535, -0.0429,  0.0784,  0.0566,\n",
      "        -0.0005, -0.0396, -0.0476,  0.0272,  0.0011, -0.0726,  0.0720,  0.0508,\n",
      "         0.0509, -0.0218,  0.0372, -0.0532,  0.0332,  0.0724,  0.0760,  0.0575,\n",
      "        -0.0327,  0.0678, -0.0349, -0.0218, -0.0810, -0.0186, -0.0231, -0.0763,\n",
      "         0.0106, -0.0662,  0.0390,  0.0214,  0.0595,  0.0289,  0.0658, -0.0316,\n",
      "         0.0412, -0.0719,  0.0292,  0.0398, -0.0882,  0.0828, -0.0789, -0.0190,\n",
      "        -0.0299, -0.0155,  0.0657,  0.0434, -0.0534, -0.0347,  0.0095,  0.0861,\n",
      "        -0.0320, -0.0577, -0.0426,  0.0342, -0.0677, -0.0682, -0.0735,  0.0865,\n",
      "        -0.0092, -0.0603,  0.0855,  0.0796, -0.0778, -0.0837,  0.0731, -0.0205,\n",
      "         0.0863, -0.0537,  0.0028,  0.0066, -0.0670, -0.0824,  0.0868, -0.0454,\n",
      "         0.0184, -0.0835,  0.0423, -0.0064, -0.0526, -0.0676,  0.0548, -0.0779,\n",
      "         0.0860, -0.0110, -0.0001,  0.0551,  0.0339, -0.0778,  0.0673, -0.0156,\n",
      "        -0.0632,  0.0233,  0.0683,  0.0449, -0.0632, -0.0135,  0.0556,  0.0327,\n",
      "        -0.0250, -0.0774,  0.0260, -0.0519,  0.0326,  0.0882,  0.0194, -0.0708,\n",
      "         0.0807,  0.0583,  0.0473,  0.0222,  0.0346,  0.0543, -0.0805, -0.0707,\n",
      "        -0.0167, -0.0163,  0.0189,  0.0124, -0.0604, -0.0363, -0.0202,  0.0501,\n",
      "         0.0376,  0.0496, -0.0475, -0.0271,  0.0793,  0.0175,  0.0172,  0.0444,\n",
      "        -0.0062,  0.0443, -0.0576, -0.0683, -0.0847,  0.0562, -0.0195, -0.0587,\n",
      "         0.0389,  0.0674, -0.0045, -0.0560,  0.0494,  0.0569, -0.0422,  0.0781,\n",
      "         0.0825, -0.0050,  0.0853, -0.0465,  0.0755, -0.0545, -0.0082, -0.0557,\n",
      "        -0.0611, -0.0597,  0.0615,  0.0362, -0.0759,  0.0458, -0.0263,  0.0755,\n",
      "        -0.0628,  0.0087,  0.0681, -0.0735,  0.0258, -0.0099,  0.0428, -0.0022],\n",
      "       requires_grad=True) torch.Size([256])\n",
      "out.weight Parameter containing:\n",
      "tensor([[ 0.0100, -0.0178, -0.0601,  ..., -0.0014,  0.0205, -0.0048],\n",
      "        [ 0.0123,  0.0498,  0.0048,  ...,  0.0061, -0.0174,  0.0145],\n",
      "        [-0.0449, -0.0018, -0.0192,  ...,  0.0406, -0.0597,  0.0151],\n",
      "        ...,\n",
      "        [-0.0065, -0.0466,  0.0422,  ..., -0.0532, -0.0253, -0.0350],\n",
      "        [ 0.0605,  0.0330, -0.0599,  ..., -0.0351,  0.0382,  0.0586],\n",
      "        [ 0.0477, -0.0242,  0.0094,  ...,  0.0617,  0.0422,  0.0487]],\n",
      "       requires_grad=True) torch.Size([10, 256])\n",
      "out.bias Parameter containing:\n",
      "tensor([ 0.0162,  0.0088,  0.0363, -0.0027,  0.0067,  0.0512, -0.0511,  0.0546,\n",
      "        -0.0496,  0.0368], requires_grad=True) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# 打印权重和偏置值\n",
    "for name, parameter in net.named_parameters():\n",
    "    print(name, parameter, parameter.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用TensorDataset和DataLoader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "bs = 64\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl  = DataLoader(dataset = train_ds, batch_size = bs, shuffle = True)\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(dataset = valid_ds, batch_size = bs * 2)\n",
    "def get_dataloader(train_ds, valid_ds, batch_size):\n",
    "    return (\n",
    "        DataLoader(dataset = train_ds, batch_size = batch_size, shuffle = True),\n",
    "        DataLoader(dataset = valid_ds, batch_size = batch_size * 2)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化器\n",
    "from torch import optim\n",
    "\n",
    "def get_model():\n",
    "    model = Mnist_NN()\n",
    "#     多返回一个优化器\n",
    "# 先用 SGD 梯度下降（更新那一些参数，model.parameters()所有参数都更新,）\n",
    "# lr：学习率，开始时尽可能小一些，迭代次数尽可能大一些\n",
    "    return model, optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1、计算loss\n",
    "# 2、更新 W，b\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "#     model(xb)：把输入放模型当中，有预测值, yb：真实值\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "#     优化器\n",
    "    if opt is not None:\n",
    "#         反向传播，算梯度    （需更新的每一层权重参数都计算出来了）\n",
    "        loss.backward()\n",
    "#     执行更新，有学习率，有梯度方向，沿着梯度方向走一个学习率大小\n",
    "        opt.step()\n",
    "#     torch 的特点，默认每次更新的梯度方向为前面所有梯度值的和\n",
    "#     zero_grad()：需要加上zero_grad()，更新梯度之后，赶紧为零\n",
    "        opt.zero_grad()\n",
    "\n",
    "#     返回 loss.item()，和 len 值，表示训练样本有多少个，要计算平均损失\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 有了 model、data，开始 train val\n",
    "# steps：数据迭代多少轮（自己定）\n",
    "# model：定义一个类 net\n",
    "# loss——func：损失函数F.cross \n",
    "# opt:优化器，梯度下降\n",
    "# train_dl, valid_dl：dataloader-构建数据的打包器\n",
    "def fit(steps, model, loss_func, opt, train_dl, valid_dl):\n",
    "#     每一次做一个遍历，steps 不是 batch，而是 epoch ，就是把整个数据集训练一遍\n",
    "# 例如 10000 个数据，batch = 100，那么 1 epoch = 100 iter，一次 epoch = 100 次迭代\n",
    "    for step in range(steps):\n",
    "#         遍历的时候注意 指定 model 的模式\n",
    "# 训练，更新每一层的 W 和 b\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "#             ！！！那前向传播 forward 函数的作用是什么\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "# 验证模式，没有梯度，不更新 W，b\n",
    "        model.eval()\n",
    "#     no_grad()：不更新参数\n",
    "        with torch.no_grad():\n",
    "# zip：python 基础，losses 和 num 是对应的\n",
    "            losses, nums = zip(\n",
    "#                 配对之后再解开，损失放在一起，样本数量放在一起\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "#     计算平均损失\n",
    "# losses，nums 都是list，做一个乘法，然后加到一起，相当于我们算一个总的损失。\n",
    "# 最后求一个平均损失\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        print('当前step:'+str(step), '验证集损失：'+str(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前step:0 验证集损失：2.272473097991943\n",
      "当前step:1 验证集损失：2.2309465896606446\n",
      "当前step:2 验证集损失：2.161337325286865\n",
      "当前step:3 验证集损失：2.045743892288208\n",
      "当前step:4 验证集损失：1.8706771821975707\n",
      "当前step:5 验证集损失：1.648413585472107\n",
      "当前step:6 验证集损失：1.4193311029434204\n",
      "当前step:7 验证集损失：1.2206530841827392\n",
      "当前step:8 验证集损失：1.0609500563621521\n",
      "当前step:9 验证集损失：0.9374064490318298\n",
      "当前step:10 验证集损失：0.8422410299301147\n",
      "当前step:11 验证集损失：0.7702293790817261\n",
      "当前step:12 验证集损失：0.7141710482597351\n",
      "当前step:13 验证集损失：0.6693857133865356\n",
      "当前step:14 验证集损失：0.6329484337329865\n",
      "当前step:15 验证集损失：0.6014164227485657\n",
      "当前step:16 验证集损失：0.5756183822631836\n",
      "当前step:17 验证集损失：0.5532853662014008\n",
      "当前step:18 验证集损失：0.5333936338901519\n",
      "当前step:19 验证集损失：0.5163269060611725\n",
      "当前step:20 验证集损失：0.5012408969879151\n",
      "当前step:21 验证集损失：0.4871598012924194\n",
      "当前step:22 验证集损失：0.4748562239646912\n",
      "当前step:23 验证集损失：0.46361174912452696\n",
      "当前step:24 验证集损失：0.4528853633880615\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_dataloader(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(25, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images:87 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for xb,yb in valid_dl:\n",
    "    outputs = model(xb)\n",
    "#     torch.max(outputs.data,1), 1：指定沿着哪个维度去做计算，对每一个样本比他的概率值，沿着每一个样本概率值的维度 1,\n",
    "# 0 是比不同样本之间的\n",
    "    _,predicted = torch.max(outputs.data,1)\n",
    "#     _占位符：返回两个值，第一个没啥用，也不起名字，占个位置\n",
    "# 每个样本当中都有预测值，_返回的是最大的那个值是什么值\n",
    "# predicted：当前的最大值他所在的位置是什么，索引也对应了预测结果（0~9）,只要预测结果（索引）\n",
    "    total += yb.size(0)# batchsize = 64，计算完 64 个样本了，total 加上去\n",
    "#     yb：真实值，每个样本本身的标签，predicted：预测值\n",
    "# .item()：tensor 格式，跑验证集时，可能要画图，tensor 格式不行，得转换成 array 数据形式\n",
    "    correct += (predicted == yb).sum().item()\n",
    "    \n",
    "print('Accuracy of the network on the 10000 test images:%d %%'%(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "认真了，我们寻到一个可用的代码进行实操，实操结束后将对前面的代码进行修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 导入依赖包\n",
    "import torch\n",
    "import torchvision\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader的用途\n",
    "- pytorch与外界数据沟通的桥梁\n",
    "- dataloader能供pytorch直接使用\n",
    "- dataloader作为python自带的numpy数据类型中转\n",
    "- 过程：numpy -> tensor -> dataset -> dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=1/7, random_state=0)  # 数据切分，训练集：测试集=6:1\n",
    "\n",
    "X_train = np.array(X_train)          # 将list转为numpy格式\n",
    "X_test = np.array(X_test)\n",
    "y_train = list(map(int, y_train))    # 将label的str类型转为int\n",
    "y_test = list(map(int, y_test))\n",
    "X_train = torch.Tensor(X_train)      # 转为浮点tensor\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)  # 转为整型tensor\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "ds_train = TensorDataset(X_train, y_train)  # 转为Dataset\n",
    "ds_test = TensorDataset(X_test, y_test)\n",
    "\n",
    "# 转为Pytorch可以直接操作彻底DataLoader\n",
    "loader_train = DataLoader(ds_train, batch_size=(64), shuffle=True)\n",
    "loader_test = DataLoader(ds_test, batch_size=(64), shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# # build nn with keras sytle\n",
    "# model = nn.Sequential()                             # 获取网络模型句柄\n",
    "# model.add_module('fc1', nn.Linear(28*28*1, 100))    # 第一层神经元，输入层\n",
    "# model.add_module('relu1', nn.ReLU())                # 第一层激活函数\n",
    "# model.add_module('fc2', nn.Linear(100, 100))        # 第二层神经元，中间层\n",
    "# model.add_module('relu2', nn.ReLU())                # 第二层激活函数\n",
    "# model.add_module('fc3', nn.Linear(100, 10))         # 第三层神经元，输出层\n",
    "# print(model)\n",
    "\n",
    "# build nn with chainer style\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_in, n_mid, n_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_in, n_mid)\n",
    "        self.fc2 = nn.Linear(n_mid, n_mid)\n",
    "        self.fc3 = nn.Linear(n_mid, n_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        h2 = F.relu(self.fc2(h1))\n",
    "        output = self.fc3(h2)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "model = Net(n_in=28*28*1, n_mid=100, n_out=10)\n",
    "print(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()                       # 选取交叉熵作为误差函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)   # 设置优化器参数，学习率0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 测试数据的准确率 ： 1141/10000 (11%)\n",
      "\n",
      "epoch0:结束\n",
      "\n",
      "epoch1:结束\n",
      "\n",
      "epoch2:结束\n",
      "\n",
      "epoch3:结束\n",
      "\n",
      "epoch4:结束\n",
      "\n",
      "epoch5:结束\n",
      "\n",
      "epoch6:结束\n",
      "\n",
      "epoch7:结束\n",
      "\n",
      "epoch8:结束\n",
      "\n",
      "epoch9:结束\n",
      "\n",
      "\n",
      " 测试数据的准确率 ： 9626/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# learning and predict process\n",
    "\n",
    "# 训练阶段\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for data, targets in loader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"epoch{}:结束\\n\".format(epoch))\n",
    "\n",
    "# 推理阶段\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in loader_test:\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += predicted.eq(targets.data.view_as(predicted)).sum()\n",
    "    \n",
    "    data_sum = len(loader_test.dataset)\n",
    "    print(\"\\n 测试数据的准确率 ： {}/{} ({:.0f}%)\\n\".\n",
    "         format(correct, data_sum, 100. * correct / data_sum))\n",
    "        \n",
    "# 训练前的分类准确率\n",
    "test()\n",
    "# 训练3个epoch过程\n",
    "for epoch in range(10):\n",
    "    train(epoch)\n",
    "# 训练后的分类准确率\n",
    "test()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果是0\n",
      "这一图像数据的正确标签是0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict particular picture\n",
    "\n",
    "# 推理第8505张图片的数字类别\n",
    "index = 8505\n",
    "model.eval()\n",
    "data = X_test[index]\n",
    "\n",
    "output = model(data)\n",
    "_, predicted = torch.max(output.data, 0)\n",
    "print(\"预测结果是{}\".format(predicted))\n",
    "\n",
    "X_test_show = (X_test[index]).numpy()\n",
    "plt.imshow(X_test_show.reshape(28, 28), cmap='gray')\n",
    "print(\"这一图像数据的正确标签是{:.0f}\".format(y_test[index]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "537b928a382ecc1da1b2ff4d48d3aa27b392cceaea5676c08c31c2fea16f125b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
