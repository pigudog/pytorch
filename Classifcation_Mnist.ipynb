{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minist Classification task\n",
    "- Construction of neural networks as well as training methods and common function analysis\n",
    "- module of **torch.nn.function** \n",
    "- modele of **nn.Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset from Minist\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pathlib的mkdir接收两个参数：\n",
    "\n",
    "- parents：如果父目录不存在，是否创建父目录。\n",
    "- exist_ok：只有在目录不存在时创建目录，目录已存在时不会抛出异常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 第二步，读数据（前两步先不用管）\n",
    "# with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "# #     (x_train, y_train)训练集的样本数据和对应的标签, (x_valid, y_valid)验证集的样本数据和对应标签\n",
    "#         ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这儿错误的原因是deeplearning.net已经不能访问了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle module\n",
    "它能够实现任意对象与文本之间的相互转化，也可以实现任意对象与二进制之间的相互转化。也就是说，pickle 可以实现 Python 对象的存储及恢复。\n",
    "\n",
    "pickle 模块提供了以下 4 个函数供我们使用：\n",
    "- dumps()：将 Python 中的对象序列化成二进制对象，并返回；\n",
    "- loads()：读取给定的二进制对象数据，并将其转换为 Python 对象；\n",
    "- dump()：将 Python 中的对象序列化成二进制对象，并写入文件；\n",
    "- load()：读取指定的序列化数据文件，并返回对象。\n",
    "\n",
    "看似强大的 pickle 模块，其实也有它的短板，即 pickle 不支持并发地访问持久性对象，在复杂的系统环境下，尤其是读取海量数据时，使用 pickle 会使整个系统的I/O读取性能成为瓶颈。这种情况下，可以使用 ZODB。\n",
    "\n",
    "ZODB 是一个健壮的、多用户的和面向对象的数据库系统，专门用于存储 Python 语言中的对象数据，它能够存储和管理任意复杂的 Python 对象，并支持事务操作和并发控制。并且，ZODB 也是在 Python 的序列化操作基础之上实现的，因此要想有效地使用 ZODB，必须先学好 pickle。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 导入依赖包\n",
    "import torch\n",
    "import torchvision\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing\n",
    "\n",
    "mnist = fetch_openml('mnist_784', data_home='.')\n",
    "X = mnist.data / 255\n",
    "y = mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel1       0.0\n",
       "pixel2       0.0\n",
       "pixel3       0.0\n",
       "pixel4       0.0\n",
       "pixel5       0.0\n",
       "            ... \n",
       "pixel780    62.0\n",
       "pixel781     0.0\n",
       "pixel782     0.0\n",
       "pixel783     0.0\n",
       "pixel784     0.0\n",
       "Length: 784, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=1/7, random_state=0)  # 数据切分，训练集：测试集=6:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01960784, 0.47058824,\n",
       "        0.78039216, 0.99607843, 1.        , 0.74901961, 0.43529412,\n",
       "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.27058824, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.48627451, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00392157, 0.43921569,\n",
       "        0.63529412, 0.03921569, 0.03921569, 0.03921569, 0.8       ,\n",
       "        0.98823529, 0.62352941, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.28627451, 0.94117647,\n",
       "        0.99215686, 0.90196078, 0.04313725, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.09411765, 0.80784314, 0.99215686,\n",
       "        0.99215686, 0.6745098 , 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01960784, 0.38823529, 0.94509804, 0.99215686, 0.99215686,\n",
       "        0.94901961, 0.46666667, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.42352941, 0.99215686, 0.99215686, 0.99215686, 0.78431373,\n",
       "        0.44313725, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.20392157, 0.99215686, 0.99215686, 0.99215686, 0.2       ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01176471, 0.16078431, 0.6745098 , 0.99215686, 0.70588235,\n",
       "        0.36470588, 0.01568627, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.63137255, 0.95294118,\n",
       "        0.99215686, 0.85882353, 0.39607843, 0.05882353, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16078431,\n",
       "        0.36862745, 0.64313725, 0.99215686, 0.7254902 , 0.2       ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00784314, 0.87058824, 0.99215686, 0.95294118,\n",
       "        0.25490196, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.52941176, 0.99215686, 0.99215686,\n",
       "        0.72941176, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.91372549, 0.99215686, 0.98431373,\n",
       "        0.63921569, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.25098039, 0.97647059, 0.99215686, 0.61960784,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0627451 , 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.03529412,\n",
       "        0.38431373, 0.92941176, 0.99215686, 0.99215686, 0.30588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.73333333, 0.59215686, 0.        ,\n",
       "        0.        , 0.        , 0.00784314, 0.26666667, 0.71372549,\n",
       "        0.99215686, 0.99215686, 0.96078431, 0.43921569, 0.03529412,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.71764706, 0.98039216, 0.57254902,\n",
       "        0.45098039, 0.45098039, 0.79215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.67058824, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.12156863, 0.59215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.95686275, 0.62745098, 0.02352941, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01960784, 0.29803922,\n",
       "        0.61176471, 0.82745098, 0.65882353, 0.74117647, 0.43137255,\n",
       "        0.15294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "# 注意从dataframe中取下来的series没有reshape的功能\n",
    "# 解决办法：用values方法将Series对象转化成numpy的ndarray，再用ndarray的reshape方法.\n",
    "X_train.iloc[1].values.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17ed28781c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOp0lEQVR4nO3df4xV9ZnH8c+j2wICUSg6osWFbfzDSgJVYjaubvyREsQ/oIE0kICskk41NaLZuEvEWBOzxKw/NmtMGqeiDBu1qYJB64+WJURWxUYwiKNuAc2QggjLYiz4qys8+8ccmhHnfs94zzn33OF5v5LJ3Huee855cuEz55z7vfd+zd0F4MR3Ut0NAGgNwg4EQdiBIAg7EARhB4L4q1buzMx46R+omLvbQMsLHdnNbIaZ/cHMdprZ0iLbAlAta3ac3cxOlrRd0g8l7Zb0uqT57v5OYh2O7EDFqjiyXyRpp7u/7+5/lvQrSbMKbA9AhYqE/WxJf+x3f3e27CvMrNPMNpvZ5gL7AlBQ5S/QuXuXpC6J03igTkWO7HskTeh3/7vZMgBtqEjYX5d0rplNMrNvS5on6Zly2gJQtqZP4939SzO7UdJvJZ0s6RF3f7u0zgCUqumht6Z2xjU7ULlK3lQDYOgg7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IIimp2zG0DBs2LBkfcyYMcn6ihUrkvWZM2cm60ePHm1Ye+qpp5LrLlu2LFnfuXNnso6vKhR2M+uVdEjSEUlfuvu0MpoCUL4yjuyXu/uBErYDoEJcswNBFA27S/qdmW0xs86BHmBmnWa22cw2F9wXgAKKnsZf4u57zOwMSevM7L/dfWP/B7h7l6QuSTIzL7g/AE0qdGR39z3Z7/2SnpZ0URlNAShf02E3s5FmNvrYbUnTJfWU1RiAchU5je+Q9LSZHdvO4+7+Yild4Rs555xzGtYefvjh5LpXXHFFoX2nxtElyb3xlducOXOS6w4fPjxZnzt3brJ+yimnNKw98MADyXXvueeeZL2nZ+gd15oOu7u/L2lKib0AqBBDb0AQhB0IgrADQRB2IAjCDgRhqaGR0nfGO+iakvcx1QcffLBh7dprry27na/Ihl4bqvL/15IlS5L1xx9/vGFt27ZtyXWfe+65ZP36669P1uvk7gP+o3BkB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgGGcfAlauXJmsL1iwoLJ9533d8/Lly5P11Edgb7rppuS61113XbJ+4ED6e07PPPPMhrXu7u7kulOmpD/QefnllyfrH330UbJeJcbZgeAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIpmxuA3mfrT7//POT9SLvlVi6dGmyfv/99yfreV8lnZI3hp83zj5u3Lim951n8uTJyfrs2bOT9UcffbTEbsrBkR0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgmCcvQUuvPDCZH3SpEnJ+kknpf8m7969u2HtlltuSa6bN9ZdpUsvvTRZz/tO+pdeeilZHz16dMPaBRdcUGjfW7ZsSdbbUe6R3cweMbP9ZtbTb9lYM1tnZjuy32OqbRNAUYM5jV8pacZxy5ZKWu/u50pan90H0MZyw+7uGyUdPG7xLEnHvtenW9LsctsCULZmr9k73H1vdvtDSR2NHmhmnZI6m9wPgJIUfoHO3T31RZLu3iWpS+ILJ4E6NTv0ts/MxktS9nt/eS0BqEKzYX9G0qLs9iJJa8tpB0BVck/jzewJSZdJGmdmuyX9XNLdkn5tZosl7ZL04yqbbHep8VxJWrZsWbI+YsSIZH3Hjh3JemosPW+e8Tr19vYm6x988EGyfscddyTrI0eObFg777zzkuvmfUdAkc/x1yU37O4+v0HpypJ7AVAh3i4LBEHYgSAIOxAEYQeCIOxAEEzZXILp06cn688//3yh7c+bNy9Zr/NjqlWaOHFisp43dJeasjn1seDBmDp1arLe09OTrFeJKZuB4Ag7EARhB4Ig7EAQhB0IgrADQRB2IAi+SroECxcuLLR+d3d3sn6ijqPnyRtHz3PNNdc0ve6mTZuS9ffee6/pbdeFIzsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBME4+yAtWrSoYW3OnDmFtn3XXXcVWh8DGzduXNPrHj58OFn/7LPPmt52XTiyA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQjLMP0pVXNp60dtiwYYW2PRTHbIeCW2+9tWEtb8rljRs3lt1O7XKP7Gb2iJntN7OefsvuNLM9ZrY1+5lZbZsAihrMafxKSTMGWP5v7j41+yk25QmAyuWG3d03SjrYgl4AVKjIC3Q3mtm27DR/TKMHmVmnmW02s80F9gWgoGbD/gtJ35M0VdJeSfc1eqC7d7n7NHef1uS+AJSgqbC7+z53P+LuRyX9UtJF5bYFoGxNhd3Mxve7+yNJ9c1PC2BQcsfZzewJSZdJGmdmuyX9XNJlZjZVkkvqlfTT6lpsD6l57PPmuH/llVeS9Y8//ripnqJLfceAlB5L//TTT5Prbtiwoame2llu2N19/gCLV1TQC4AK8XZZIAjCDgRB2IEgCDsQBGEHguAjri2QN4zz+eeft6iToeWss85K1u+7r+EbN3OtW7cuWX/ttdea3na74sgOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0Ewzp4ZMWJEsj5p0qSmt71r166m1z2R5Y2j33777cn6aaedlqyn3r9w7733Jtc9EXFkB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgGGfPnHrqqcn6xRdf3KJOTixnnHFGw9qzzz6bXHfKlCmF9j137tyGtVdffbXQtocijuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EATj7JnU9L6S9MUXXzSsDR8+PLnujBkzkvVVq1Yl60eOHEnW6zR58uRk/c0336xs33mfSX/hhRcq2/dQlHtkN7MJZrbBzN4xs7fNbEm2fKyZrTOzHdnvMdW3C6BZgzmN/1LSP7r79yX9raSfmdn3JS2VtN7dz5W0PrsPoE3lht3d97r7G9ntQ5LelXS2pFmSurOHdUuaXVGPAErwja7ZzWyipB9I+r2kDnffm5U+lNTRYJ1OSZ0FegRQgkG/Gm9moyStlnSzu/+pf83dXZIPtJ67d7n7NHefVqhTAIUMKuxm9i31Bf0xd1+TLd5nZuOz+nhJ+6tpEUAZrO+gnHiAmanvmvygu9/cb/k9kv7X3e82s6WSxrr7P+VsK72zNjZ79uyGtZUrVybXHTVqVLK+evXqZH358uXJehELFy5M1k8//fRkfcGCBcl63v+vlO3btyfrnZ3pq8OXX3656X0PZe5uAy0fzDX730laKOktM9uaLbtN0t2Sfm1miyXtkvTjEvoEUJHcsLv7y5IG/Esh6cpy2wFQFd4uCwRB2IEgCDsQBGEHgiDsQBC54+yl7mwIj7OnPPTQQ8n64sWLC22/760OjbXy3/B4eb0dOnSoYW3Tpk3JdW+44YZkvbe3N1mPqtE4O0d2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCcfYSjB49Olm/+uqrk/W8r5rO+8x5nePsjz32WLK+Zs2ahrW1a9eW3Q7EODsQHmEHgiDsQBCEHQiCsANBEHYgCMIOBME4+xDQ0THgzFp/cdVVVzWs5Y3hf/LJJ8n6iy++mKw/+eSTyTpaj3F2IDjCDgRB2IEgCDsQBGEHgiDsQBCEHQhiMPOzT5C0SlKHJJfU5e7/bmZ3SvqJpP/JHnqbuz+fsy3G2YGKNRpnH0zYx0sa7+5vmNloSVskzVbffOyH3f3ewTZB2IHqNQr7YOZn3ytpb3b7kJm9K+nsctsDULVvdM1uZhMl/UDS77NFN5rZNjN7xMzGNFin08w2m9nmYq0CKGLQ7403s1GSXpL0L+6+xsw6JB1Q33X8Xeo71b8uZxucxgMVa/qaXZLM7FuSfiPpt+5+/wD1iZJ+4+6Tc7ZD2IGKNf1BGOubpnOFpHf7Bz174e6YH0nqKdokgOoM5tX4SyT9l6S3JB3NFt8mab6kqeo7je+V9NPsxbzUtjiyAxUrdBpfFsIOVI/PswPBEXYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4LI/cLJkh2QtKvf/XHZsnbUrr21a18SvTWrzN7+ulGhpZ9n/9rOzTa7+7TaGkho197atS+J3prVqt44jQeCIOxAEHWHvavm/ae0a2/t2pdEb81qSW+1XrMDaJ26j+wAWoSwA0HUEnYzm2FmfzCznWa2tI4eGjGzXjN7y8y21j0/XTaH3n4z6+m3bKyZrTOzHdnvAefYq6m3O81sT/bcbTWzmTX1NsHMNpjZO2b2tpktyZbX+twl+mrJ89bya3YzO1nSdkk/lLRb0uuS5rv7Oy1tpAEz65U0zd1rfwOGmf29pMOSVh2bWsvM/lXSQXe/O/tDOcbd/7lNertT33Aa74p6azTN+D+oxueuzOnPm1HHkf0iSTvd/X13/7OkX0maVUMfbc/dN0o6eNziWZK6s9vd6vvP0nINemsL7r7X3d/Ibh+SdGya8Vqfu0RfLVFH2M+W9Md+93erveZ7d0m/M7MtZtZZdzMD6Og3zdaHkjrqbGYAudN4t9Jx04y3zXPXzPTnRfEC3ddd4u4XSLpK0s+y09W25H3XYO00dvoLSd9T3xyAeyXdV2cz2TTjqyXd7O5/6l+r87kboK+WPG91hH2PpAn97n83W9YW3H1P9nu/pKfVd9nRTvYdm0E3+72/5n7+wt33ufsRdz8q6Zeq8bnLphlfLekxd1+TLa79uRuor1Y9b3WE/XVJ55rZJDP7tqR5kp6poY+vMbOR2QsnMrORkqar/aaifkbSouz2Iklra+zlK9plGu9G04yr5ueu9unP3b3lP5Jmqu8V+fckLaujhwZ9/Y2kN7Oft+vuTdIT6jut+z/1vbaxWNJ3JK2XtEPSf0oa20a9/Yf6pvbepr5gja+pt0vUd4q+TdLW7Gdm3c9doq+WPG+8XRYIghfogCAIOxAEYQeCIOxAEIQdCIKwA0EQdiCI/wdQVaJxSRpUQAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "# x_train[0] 一维的784个数据.reshape成 28*28 的，cmap 用一个灰度图去做\n",
    "pyplot.imshow(X_train.iloc[2].values.reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       0.0       0.0       0.0       0.0  \n",
       "1       0.0       0.0       0.0       0.0  \n",
       "2       0.0       0.0       0.0       0.0  \n",
       "3       0.0       0.0       0.0       0.0  \n",
       "4       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28926    7\n",
       "9080     3\n",
       "52804    0\n",
       "28094    1\n",
       "46585    2\n",
       "Name: class, dtype: category\n",
       "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56267</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14849</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62726</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47180</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "10840     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "56267     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "14849     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "62726     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "47180     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "10840      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "56267      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "14849      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "62726      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "47180      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "10840       0.0       0.0       0.0       0.0       0.0  \n",
       "56267       0.0       0.0       0.0       0.0       0.0  \n",
       "14849       0.0       0.0       0.0       0.0       0.0  \n",
       "62726       0.0       0.0       0.0       0.0       0.0  \n",
       "47180       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)          # 将features转为numpy格式\n",
    "X_test = np.array(X_test)\n",
    "# y_train = list(map(int, y_train))    # 将label的str类型转为int\n",
    "# y_test = list(map(int, y_test))\n",
    "y_train = np.array(y_train,dtype=float)   # 将label的str类型转为int\n",
    "y_test = np.array(y_test,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转化为数据格式\n",
    "import torch\n",
    "# torch 放在 GPU 中跑，底层结构不同。tensor 张量（矩阵）一切处理的数据都是张量，TensorFlow 张量（矩阵）在流动，矩阵在变换\n",
    "# ndarray格式 torch 用不了\n",
    "# 使用 map 将数组格式映射为 tensor 格式\n",
    "# x_train, y_train, x_valid, y_valid = map(torch.from_numpy(), (X_train, y_train, X_test, y_test))\n",
    "x_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train,dtype=torch.long)\n",
    "x_valid = torch.tensor(X_test,dtype=torch.float32)\n",
    "y_valid = torch.tensor(y_test,dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.functional\n",
    "\n",
    "一般情况下，如果模型有待学习的参数（卷积层等），最好用nn.Module，其他情况nn.functional(如激活函数、损失函数)相对更简单直接一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置损失函数和全连接层\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 设定损失函数为交叉熵：分类问题\n",
    "loss_func = F.cross_entropy# 用loss_func的时候要传入（pre,y）预测值和标签\n",
    "\n",
    "# 全连接层\n",
    "def model(xb):\n",
    "    return xb.mm(weights) + bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17.0611, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 设置参数set up parameters\n",
    "# batchsize：一次性训练的样本个数\n",
    "bs = 64\n",
    "# xw + b,w哪里来，可以自己做初始化，权重参数随机初始化，\n",
    "# x 的规格。64*784（每个样本 784 个特征）\n",
    "xb = x_train[0:bs]  # a mini-batch from x\n",
    "yb = y_train[0:bs]\n",
    "# 随机初始化权重参数 w：784*28 ，影藏层的features设为28个，需要梯度\n",
    "weights = torch.randn([784, 28], dtype = torch.float,  requires_grad = True) \n",
    "# 偏执可以是随机数，可以常数，对结果的影响是非常小的,但是这儿要注意一点，weights是不能全为0的，这样就会导致没有我们想要的 asymmetry\n",
    "bias = torch.ones(28, requires_grad=True)\n",
    "\n",
    "# model(xb) 预测值, yb标签\n",
    "print(loss_func(model(xb), yb))\n",
    "# loss函数会自动进行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 28])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb).shape ## 证明执行了broadcasting的python的特性，我们在下面给出证明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        ...,\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb)-xb.mm(weights) ## 这个也同时证明了我们的loss函数会自动对于行向量进行求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 3, 0, 1, 2, 0, 7, 6, 5, 5, 8, 2, 7, 6, 8, 1, 8, 5, 0, 1, 8, 4, 7, 3,\n",
       "        9, 4, 5, 9, 8, 1, 1, 1, 7, 2, 4, 0, 6, 4, 5, 1, 9, 4, 9, 0, 1, 5, 9, 1,\n",
       "        6, 4, 1, 1, 5, 8, 7, 7, 7, 0, 3, 7, 1, 5, 7, 9])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建一个model来更加简化代码\n",
    "- 必须继承nn.Module且在其构造函数中需要调用nn.Module的构造函数\n",
    "- 无需写反向传播函数，nn.Module能够利用autograd自动实现反向传播\n",
    "- Module中的可学习参数可以通过named_parameters()或者parameters()返回迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化网络结构\n",
    "from torch import nn\n",
    "\n",
    "# 继承不能改\n",
    "class Mnist_NN(nn.Module):\n",
    "#     构造函数（接下来你会用到哪一层，哪一些操作，每一层的设计要给出来），先定义好第一个 FC，第二个 FC，输出层，dropout\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#       第一个隐层：输入 784 个像素点（第一行有 784 列），输出 128 个特征（输出 128 行）\n",
    "        self.hidden1 = nn.Linear(784, 128)\n",
    "#       第二个隐层：输入（第一个隐层的输出） 128 个第一层的特征，输出 256 个第二层的特征\n",
    "        self.hidden2 = nn.Linear(128, 256)\n",
    "#       输出层：转成是个类别的值\n",
    "        self.out  = nn.Linear(256, 10)\n",
    "#       按照 50%的比例来杀死特征点，防止过拟合等现象的出现\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "# torch 中的前向传播是需要自己做定义，反向传播是自动的，torch 反向传播一行代码给你实现\n",
    "# 前向传播\n",
    "# x 是 batch 值，x 每一步要走什么都是要自己定义的\n",
    "    def forward(self, x):\n",
    "#       第一步走h1，\n",
    "        x = F.relu(self.hidden1(x))\n",
    "#       每一个 FC 层都要加上 dropout，除了最后一层输出层\n",
    "        x = self.dropout(x)\n",
    "#       h2 层\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.dropout(x)\n",
    "#       输出层  \n",
    "        x = self.out(x)\n",
    "        return x\n",
    "        \n",
    "# 首先定义好自己的网络结构，定义一个类，类当中构造函数要用啥，每一层要怎么去走，要自己去定义\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于 Dropout 可以防止过拟合，出处：深度学习领域大神 Hinton，在2012年文献：《Improving neural networks by preventing co-adaptation of feature detectors》提出的。\n",
    "\n",
    "运用了dropout的训练过程，相当于训练了很多个只有半数隐层单元的神经网络（后面简称为“半数网络”），每一个这样的半数网络，都可以给出一个分类结果，这些结果有的是正确的，有的是错误的。随着训练的进行，大部分半数网络都可以给出正确的分类结果，那么少数的错误分类结果就不会对最终结果造成大的影响。\n",
    "\n",
    "在每次训练的时候，让一半的特征检测器停过工作，这样可以提高网络的泛化能力，Hinton把它称之为dropout。\n",
    "\n",
    "Hinton认为：过拟合，可以通过阻止某些特征的协同作用来缓解。在每次训练的时候，每个神经元有百分之50的几率被移除，这样可以让一个神经元的出现不应该依赖于另外一个神经元。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist_NN(\n",
      "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (hidden2): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Mnist_NN()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1.weight Parameter containing:\n",
      "tensor([[-0.0322, -0.0247,  0.0303,  ..., -0.0073,  0.0057,  0.0230],\n",
      "        [ 0.0046,  0.0335,  0.0141,  ...,  0.0134, -0.0114,  0.0148],\n",
      "        [-0.0184, -0.0245, -0.0100,  ...,  0.0321, -0.0070,  0.0341],\n",
      "        ...,\n",
      "        [-0.0096, -0.0089, -0.0277,  ...,  0.0158, -0.0069, -0.0307],\n",
      "        [ 0.0310, -0.0015,  0.0138,  ..., -0.0296,  0.0272,  0.0275],\n",
      "        [-0.0227,  0.0254, -0.0059,  ...,  0.0314,  0.0113,  0.0048]],\n",
      "       requires_grad=True) torch.Size([128, 784])\n",
      "hidden1.bias Parameter containing:\n",
      "tensor([-0.0297, -0.0331,  0.0324, -0.0132, -0.0152, -0.0023,  0.0120, -0.0008,\n",
      "        -0.0041, -0.0040, -0.0068,  0.0278, -0.0057, -0.0318, -0.0285,  0.0155,\n",
      "        -0.0109,  0.0237, -0.0336,  0.0004, -0.0301,  0.0006,  0.0227, -0.0294,\n",
      "        -0.0114,  0.0221,  0.0197, -0.0357,  0.0028, -0.0328,  0.0133,  0.0336,\n",
      "        -0.0234, -0.0280,  0.0053,  0.0024, -0.0231,  0.0181,  0.0118,  0.0168,\n",
      "        -0.0319, -0.0216, -0.0173, -0.0117, -0.0034, -0.0307, -0.0253, -0.0049,\n",
      "        -0.0124, -0.0268, -0.0135, -0.0215, -0.0226,  0.0051,  0.0018, -0.0186,\n",
      "         0.0079,  0.0043,  0.0312, -0.0265, -0.0303, -0.0234,  0.0234, -0.0285,\n",
      "         0.0028, -0.0154, -0.0083, -0.0207,  0.0049, -0.0038,  0.0210, -0.0041,\n",
      "         0.0078,  0.0261, -0.0292, -0.0247,  0.0130,  0.0108, -0.0163, -0.0212,\n",
      "         0.0332, -0.0025, -0.0256, -0.0188, -0.0162, -0.0151,  0.0333, -0.0015,\n",
      "         0.0051,  0.0221,  0.0004, -0.0095,  0.0225,  0.0008, -0.0355,  0.0049,\n",
      "        -0.0301,  0.0075, -0.0114,  0.0209,  0.0310,  0.0003,  0.0294,  0.0077,\n",
      "         0.0111, -0.0204,  0.0274,  0.0290,  0.0119,  0.0051,  0.0036, -0.0138,\n",
      "        -0.0121,  0.0110,  0.0208,  0.0170,  0.0115, -0.0052, -0.0037, -0.0355,\n",
      "         0.0317,  0.0278,  0.0211, -0.0256,  0.0028, -0.0135, -0.0077, -0.0271],\n",
      "       requires_grad=True) torch.Size([128])\n",
      "hidden2.weight Parameter containing:\n",
      "tensor([[ 0.0299,  0.0030,  0.0822,  ..., -0.0143, -0.0789,  0.0413],\n",
      "        [-0.0584, -0.0306,  0.0254,  ..., -0.0520,  0.0751,  0.0498],\n",
      "        [-0.0044, -0.0346, -0.0173,  ..., -0.0316,  0.0232,  0.0835],\n",
      "        ...,\n",
      "        [-0.0015, -0.0732,  0.0006,  ..., -0.0299,  0.0879,  0.0810],\n",
      "        [-0.0205,  0.0017, -0.0495,  ...,  0.0288, -0.0175,  0.0725],\n",
      "        [-0.0017,  0.0563,  0.0567,  ..., -0.0475, -0.0069,  0.0847]],\n",
      "       requires_grad=True) torch.Size([256, 128])\n",
      "hidden2.bias Parameter containing:\n",
      "tensor([ 0.0562, -0.0790,  0.0472,  0.0308,  0.0736, -0.0883,  0.0145,  0.0395,\n",
      "        -0.0576,  0.0507, -0.0435,  0.0622, -0.0871, -0.0357, -0.0236, -0.0156,\n",
      "         0.0039,  0.0489,  0.0227, -0.0520,  0.0114, -0.0587, -0.0379,  0.0777,\n",
      "        -0.0210, -0.0354, -0.0691, -0.0373,  0.0134, -0.0122,  0.0185,  0.0179,\n",
      "        -0.0812,  0.0195,  0.0132,  0.0359,  0.0028, -0.0399,  0.0655, -0.0464,\n",
      "        -0.0609,  0.0498, -0.0737,  0.0654, -0.0199,  0.0760,  0.0003,  0.0837,\n",
      "        -0.0464,  0.0687,  0.0265,  0.0334, -0.0440,  0.0836,  0.0775, -0.0556,\n",
      "        -0.0448,  0.0740,  0.0595,  0.0828, -0.0729,  0.0797,  0.0424, -0.0813,\n",
      "         0.0082, -0.0755, -0.0270,  0.0587, -0.0726, -0.0366, -0.0005,  0.0191,\n",
      "         0.0431, -0.0776,  0.0406, -0.0686,  0.0316,  0.0558, -0.0713, -0.0479,\n",
      "         0.0571, -0.0475, -0.0463,  0.0398, -0.0150,  0.0816, -0.0745,  0.0084,\n",
      "        -0.0179, -0.0580,  0.0394, -0.0679,  0.0545, -0.0429, -0.0869,  0.0281,\n",
      "         0.0714, -0.0071,  0.0700,  0.0818, -0.0519, -0.0879, -0.0770,  0.0801,\n",
      "        -0.0233,  0.0395,  0.0235, -0.0578, -0.0441,  0.0610, -0.0393,  0.0667,\n",
      "         0.0728,  0.0174,  0.0768, -0.0674, -0.0437,  0.0444,  0.0507, -0.0615,\n",
      "        -0.0316,  0.0119, -0.0474, -0.0392,  0.0345, -0.0205,  0.0098, -0.0547,\n",
      "        -0.0174,  0.0305,  0.0831,  0.0703, -0.0765,  0.0876,  0.0230,  0.0465,\n",
      "        -0.0283,  0.0481,  0.0198, -0.0881,  0.0559,  0.0541,  0.0598,  0.0130,\n",
      "         0.0508,  0.0566,  0.0729,  0.0318,  0.0188, -0.0862,  0.0044, -0.0718,\n",
      "        -0.0632,  0.0122, -0.0633,  0.0837,  0.0290, -0.0506, -0.0777, -0.0269,\n",
      "        -0.0102, -0.0686, -0.0012,  0.0401,  0.0397, -0.0581, -0.0672,  0.0714,\n",
      "        -0.0728,  0.0679, -0.0234, -0.0711,  0.0851,  0.0035, -0.0280,  0.0233,\n",
      "         0.0035, -0.0421, -0.0007, -0.0517, -0.0778, -0.0870, -0.0865, -0.0131,\n",
      "        -0.0718, -0.0705, -0.0148,  0.0541, -0.0628, -0.0132,  0.0122, -0.0735,\n",
      "        -0.0697,  0.0100, -0.0060,  0.0159, -0.0632, -0.0655, -0.0743,  0.0364,\n",
      "        -0.0253,  0.0110, -0.0737, -0.0410,  0.0798, -0.0323,  0.0033,  0.0766,\n",
      "        -0.0137,  0.0600, -0.0520,  0.0489,  0.0755,  0.0348,  0.0169,  0.0381,\n",
      "         0.0620, -0.0290,  0.0640, -0.0450,  0.0437,  0.0489, -0.0808, -0.0635,\n",
      "         0.0407, -0.0387, -0.0011,  0.0529,  0.0011,  0.0403, -0.0465, -0.0681,\n",
      "         0.0149,  0.0455, -0.0294,  0.0711, -0.0542, -0.0615,  0.0610,  0.0683,\n",
      "         0.0783, -0.0056, -0.0509, -0.0114,  0.0729, -0.0175, -0.0100, -0.0149,\n",
      "        -0.0681, -0.0088, -0.0214, -0.0650,  0.0210, -0.0125, -0.0808,  0.0670],\n",
      "       requires_grad=True) torch.Size([256])\n",
      "out.weight Parameter containing:\n",
      "tensor([[ 0.0445, -0.0531,  0.0295,  ...,  0.0366,  0.0309, -0.0233],\n",
      "        [ 0.0557, -0.0200, -0.0449,  ...,  0.0022, -0.0202, -0.0106],\n",
      "        [-0.0446,  0.0072, -0.0363,  ...,  0.0542, -0.0278, -0.0045],\n",
      "        ...,\n",
      "        [-0.0273, -0.0024, -0.0500,  ..., -0.0116,  0.0325, -0.0144],\n",
      "        [ 0.0355, -0.0327, -0.0432,  ..., -0.0006, -0.0245,  0.0399],\n",
      "        [-0.0437,  0.0088, -0.0210,  ...,  0.0617, -0.0295,  0.0323]],\n",
      "       requires_grad=True) torch.Size([10, 256])\n",
      "out.bias Parameter containing:\n",
      "tensor([-0.0017,  0.0154,  0.0177, -0.0048,  0.0348,  0.0464,  0.0024, -0.0381,\n",
      "        -0.0338, -0.0325], requires_grad=True) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# 打印权重和偏置值\n",
    "for name, parameter in net.named_parameters():\n",
    "    print(name, parameter, parameter.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习和使用TensorDataset 和 DataLoader 来简化问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用TensorDataset和DataLoader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "bs = 64\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl  = DataLoader(dataset = train_ds, batch_size = bs, shuffle = True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(dataset = valid_ds, batch_size = bs * 2) # *2只是为了加快我们的update，没有什么特殊意义\n",
    "\n",
    "def get_dataloader(train_ds, valid_ds, batch_size):\n",
    "    return (\n",
    "        DataLoader(dataset = train_ds, batch_size = batch_size, shuffle = True),\n",
    "        DataLoader(dataset = valid_ds, batch_size = batch_size * 2)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一般再训练模型时加上model.train(),这样就会正常使用Batch Normalization and Dropout\n",
    "- 测试的时候一般选择model.eval(),这样就不会使用Batch Normalization and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.tensor([[1,2,3],[3,4,5]])) # len只计算有几行，也就是沿着axis = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1、计算loss\n",
    "# 2、更新 W，b\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    #model(xb)：把输入放模型当中，有预测值, yb：真实值\n",
    "    loss = loss_func(model(xb), yb)\n",
    "    \n",
    "    #如果传进来一个优化器\n",
    "    if opt is not None:\n",
    "#         反向传播，算梯度    （需更新的每一层权重参数都计算出来了）\n",
    "        loss.backward()\n",
    "#     执行更新，有学习率，有梯度方向，沿着梯度方向走一个学习率大小\n",
    "        opt.step()\n",
    "#     torch 的特点，默认每次更新的梯度方向为前面所有梯度值的和\n",
    "#     zero_grad()：需要加上zero_grad()，更新梯度之后，赶紧为零\n",
    "        opt.zero_grad()\n",
    "\n",
    "#     返回 loss.item()，和 len 值，表示训练样本有多少个，要计算平均损失\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化器\n",
    "from torch import optim\n",
    "\n",
    "def get_model():\n",
    "    model = Mnist_NN()\n",
    "#     多返回一个优化器\n",
    "# 先用 SGD 梯度下降（更新那一些参数，model.parameters()所有参数都更新,）\n",
    "# lr：学习率，开始时尽可能小一些，迭代次数尽可能大一些\n",
    "    return model, optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 10, 18])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = [1,2,3]\n",
    "list2 = [4,5,6]\n",
    "np.multiply(list1,list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 有了 model、data，开始 train value\n",
    "# steps：数据迭代多少轮（自己定）\n",
    "# model：定义一个类 net\n",
    "# loss——func：损失函数F.cross_entropy\n",
    "# opt:优化器，梯度下降sgd\n",
    "# train_dl, valid_dl：dataloader-构建数据的打包器\n",
    "\n",
    "\n",
    "def fit(steps, model, loss_func, opt, train_dl, valid_dl):\n",
    "#     每一次做一个遍历，steps 不是 batch，而是 epoch ，就是把整个数据集训练一遍\n",
    "# 例如 10000 个数据，batch = 100，那么 1 epoch = 100 iter，一次 epoch = 100 次迭代\n",
    "    for step in range(steps): #遍历的时候注意 指定 model 的模式训练，更新每一层的 W 和 b\n",
    "        # 训练\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:  #！！！那前向传播 forward 函数的作用是什么\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        # 验证模式，没有梯度，不更新 W，b\n",
    "        model.eval()\n",
    "        #no_grad()：不更新参数\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "\n",
    "# losses，nums 都是list，做一个乘法，然后加到一起，相当于我们算一个总的损失。\n",
    "# 最后求一个平均损失\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        print('当前step:'+str(step), '验证集损失：'+str(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前step:0 验证集损失：2.274196497344971\n",
      "当前step:1 验证集损失：2.233715855407715\n",
      "当前step:2 验证集损失：2.1696446811676027\n",
      "当前step:3 验证集损失：2.0623899013519287\n",
      "当前step:4 验证集损失：1.8908672775268556\n",
      "当前step:5 验证集损失：1.661969122314453\n",
      "当前step:6 验证集损失：1.4266062288284302\n",
      "当前step:7 验证集损失：1.2265777341842652\n",
      "当前step:8 验证集损失：1.0711992437362672\n",
      "当前step:9 验证集损失：0.9551382435798645\n",
      "当前step:10 验证集损失：0.8662317079544067\n",
      "当前step:11 验证集损失：0.7943822613716125\n",
      "当前step:12 验证集损失：0.7370139165878296\n",
      "当前step:13 验证集损失：0.6883831130981445\n",
      "当前step:14 验证集损失：0.6479397739410401\n",
      "当前step:15 验证集损失：0.6130652653694153\n",
      "当前step:16 验证集损失：0.5839456032752991\n",
      "当前step:17 验证集损失：0.5583670346260071\n",
      "当前step:18 验证集损失：0.5367842405319214\n",
      "当前step:19 验证集损失：0.5170585851669312\n",
      "当前step:20 验证集损失：0.5006048397064209\n",
      "当前step:21 验证集损失：0.4851410976886749\n",
      "当前step:22 验证集损失：0.4718759995937347\n",
      "当前step:23 验证集损失：0.4592939622402191\n",
      "当前step:24 验证集损失：0.4486901958942413\n",
      "当前step:25 验证集损失：0.43844605164527894\n",
      "当前step:26 验证集损失：0.4291864957332611\n",
      "当前step:27 验证集损失：0.4206536694049835\n",
      "当前step:28 验证集损失：0.4130505048274994\n",
      "当前step:29 验证集损失：0.40592255606651306\n"
     ]
    }
   ],
   "source": [
    "# 三步走：数据，模型，训练\n",
    "train_dl, valid_dl = get_dataloader(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(30, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images:88 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for xb,yb in valid_dl:\n",
    "    outputs = model(xb)\n",
    "#     torch.max(outputs.data,1), 1：指定沿着哪个维度去做计算，对每一个样本比他的概率值，沿着每一个样本概率值的维度 1,\n",
    "# 0 是比不同样本之间的\n",
    "    _,predicted = torch.max(outputs.data,1)\n",
    "#     _占位符：返回两个值，第一个没啥用，也不起名字，占个位置\n",
    "# 每个样本当中都有预测值，_返回的是最大的那个值是什么值\n",
    "# predicted：当前的最大值他所在的位置是什么，索引也对应了预测结果（0~9）,只要预测结果（索引）\n",
    "    total += yb.size(0)# batchsize = 64，计算完 64 个样本了，total 加上去\n",
    "#     yb：真实值，每个样本本身的标签，predicted：预测值\n",
    "# .item()：tensor 格式，跑验证集时，可能要画图，tensor 格式不行，得转换成 array 数据形式\n",
    "    correct += (predicted == yb).sum().item()\n",
    "    \n",
    "print('Accuracy of the network on the 10000 test images:%d %%'%(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "认真了，我们寻到一个可用的代码进行实操，实操结束后将对前面的代码进行修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 导入依赖包\n",
    "import torch\n",
    "import torchvision\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader的用途\n",
    "- pytorch与外界数据沟通的桥梁\n",
    "- dataloader能供pytorch直接使用\n",
    "- dataloader作为python自带的numpy数据类型中转\n",
    "- 过程：numpy -> tensor -> dataset -> dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=1/7, random_state=0)  # 数据切分，训练集：测试集=6:1\n",
    "\n",
    "X_train = np.array(X_train)          # 将list转为numpy格式\n",
    "X_test = np.array(X_test)\n",
    "y_train = list(map(int, y_train))    # 将label的str类型转为int\n",
    "y_test = list(map(int, y_test))\n",
    "X_train = torch.Tensor(X_train)      # 转为浮点tensor\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)  # 转为整型tensor\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "ds_train = TensorDataset(X_train, y_train)  # 转为Dataset\n",
    "ds_test = TensorDataset(X_test, y_test)\n",
    "\n",
    "# 转为Pytorch可以直接操作彻底DataLoader\n",
    "loader_train = DataLoader(ds_train, batch_size=(64), shuffle=True)\n",
    "loader_test = DataLoader(ds_test, batch_size=(64), shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# # build nn with keras sytle\n",
    "# model = nn.Sequential()                             # 获取网络模型句柄\n",
    "# model.add_module('fc1', nn.Linear(28*28*1, 100))    # 第一层神经元，输入层\n",
    "# model.add_module('relu1', nn.ReLU())                # 第一层激活函数\n",
    "# model.add_module('fc2', nn.Linear(100, 100))        # 第二层神经元，中间层\n",
    "# model.add_module('relu2', nn.ReLU())                # 第二层激活函数\n",
    "# model.add_module('fc3', nn.Linear(100, 10))         # 第三层神经元，输出层\n",
    "# print(model)\n",
    "\n",
    "# build nn with chainer style\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_in, n_mid, n_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_in, n_mid)\n",
    "        self.fc2 = nn.Linear(n_mid, n_mid)\n",
    "        self.fc3 = nn.Linear(n_mid, n_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        h2 = F.relu(self.fc2(h1))\n",
    "        output = self.fc3(h2)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "model = Net(n_in=28*28*1, n_mid=100, n_out=10)\n",
    "print(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()                       # 选取交叉熵作为误差函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)   # 设置优化器参数，学习率0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 测试数据的准确率 ： 1141/10000 (11%)\n",
      "\n",
      "epoch0:结束\n",
      "\n",
      "epoch1:结束\n",
      "\n",
      "epoch2:结束\n",
      "\n",
      "epoch3:结束\n",
      "\n",
      "epoch4:结束\n",
      "\n",
      "epoch5:结束\n",
      "\n",
      "epoch6:结束\n",
      "\n",
      "epoch7:结束\n",
      "\n",
      "epoch8:结束\n",
      "\n",
      "epoch9:结束\n",
      "\n",
      "\n",
      " 测试数据的准确率 ： 9626/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# learning and predict process\n",
    "\n",
    "# 训练阶段\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for data, targets in loader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"epoch{}:结束\\n\".format(epoch))\n",
    "\n",
    "# 推理阶段\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in loader_test:\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += predicted.eq(targets.data.view_as(predicted)).sum()\n",
    "    \n",
    "    data_sum = len(loader_test.dataset)\n",
    "    print(\"\\n 测试数据的准确率 ： {}/{} ({:.0f}%)\\n\".\n",
    "         format(correct, data_sum, 100. * correct / data_sum))\n",
    "        \n",
    "# 训练前的分类准确率\n",
    "test()\n",
    "# 训练3个epoch过程\n",
    "for epoch in range(10):\n",
    "    train(epoch)\n",
    "# 训练后的分类准确率\n",
    "test()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果是0\n",
      "这一图像数据的正确标签是0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict particular picture\n",
    "\n",
    "# 推理第8505张图片的数字类别\n",
    "index = 8505\n",
    "model.eval()\n",
    "data = X_test[index]\n",
    "\n",
    "output = model(data)\n",
    "_, predicted = torch.max(output.data, 0)\n",
    "print(\"预测结果是{}\".format(predicted))\n",
    "\n",
    "X_test_show = (X_test[index]).numpy()\n",
    "plt.imshow(X_test_show.reshape(28, 28), cmap='gray')\n",
    "print(\"这一图像数据的正确标签是{:.0f}\".format(y_test[index]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "537b928a382ecc1da1b2ff4d48d3aa27b392cceaea5676c08c31c2fea16f125b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
